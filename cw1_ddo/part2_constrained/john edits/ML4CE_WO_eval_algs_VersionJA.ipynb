{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This note book leads through the workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import all necessary information we need for our problem \n",
    "Do not change anything here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ML4CE_WO_algorithms import *\n",
    "from ML4CE_WO_utils import *\n",
    "from ML4CE_WO_MyAlg import *\n",
    "from ML4CE_WO_MyAlgcopy import *\n",
    "\n",
    "functions_test = [\"WO_f\"]\n",
    "\n",
    "# Number of input dimensions for WO\n",
    "N_x_l = [2]\n",
    "\n",
    "# Iterate from 10 different starting points\n",
    "reps = 10\n",
    "\n",
    "#  Specify budget\n",
    "f_eval_l = [20]\n",
    "\n",
    "# Specify bounds\n",
    "bounds = np.array([[4.0, 7.0], [70.0, 100.0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's specify the algorithms we want to use. Your \"competitors\" in the group work will be your classmates. However, we've decided to give you some (quite capable) sparring partners here - don't worry if your algorithm's performance does not live up to these standards, as your grading will be wtih respect to your classmates performances :-). Once you've coded your algorithm in `ML4CE_WO_algorithms.py` you may add it's name in the following list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms_test = [\n",
    "    #COBYLA,\n",
    "    #COBYQA, \n",
    "    YourAlg,\n",
    "    #### add name of your algorithm here #####\n",
    "    # after we make a function, we add it here #\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here on, you should be able to run each of the following cells. The first function `ML4CE_con_eval` evaluates your algorithm from 10 different starting points (=10 reps) with a budget of 20 objective function evaluations per repetition. Then `ML4CE_con_graph_abs` and `ML4CE_con_graph_abs_g1_coursework` will visualize the convergence of your algorithm and the sparring partners performance, as well as the constraint handling. Finally, `ML4CE_con_table_coursework` and `ML4CE_con_table_plot_coursework` will apply the benchmarking procedure based on the trajectories and will summarize the results in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================  WO_f D2\n",
      "==  YourAlg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]c:\\Users\\johnj\\OneDrive - Imperial College London\\Python\\Imperial-ML4CE-Course\\cw1_ddo\\part2_constrained\\ML4CE_WO_MyAlg.py:121: RuntimeWarning: Method L-BFGS-B cannot handle constraints.\n",
      "  res = minimize(min_obj, x0=x0.flatten(), bounds=bounds, constraints=cons, method='L-BFGS-B')\n",
      "c:\\Users\\johnj\\OneDrive - Imperial College London\\Python\\Imperial-ML4CE-Course\\cw1_ddo\\part2_constrained\\ML4CE_WO_MyAlg.py:90: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sigma = np.sqrt(np.diag(sigma))\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m info, trajectories \u001b[38;5;241m=\u001b[39m ML4CE_con_eval(N_x_l, f_eval_l, functions_test, algorithms_test, reps, bounds\u001b[38;5;241m=\u001b[39mbounds)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m### Rank will return NaNs when only a single algorithms is in algorithms_list\u001b[39;00m\n\u001b[0;32m      3\u001b[0m test_res_raw, test_res_norm, vio_dict\u001b[38;5;241m=\u001b[39m ML4CE_con_table_coursework(trajectories, algorithms_test, functions_test, N_x_l)\n",
      "File \u001b[1;32mc:\\Users\\johnj\\OneDrive - Imperial College London\\Python\\Imperial-ML4CE-Course\\cw1_ddo\\part2_constrained\\ML4CE_WO_utils.py:106\u001b[0m, in \u001b[0;36mML4CE_con_eval\u001b[1;34m(N_x_l, f_eval_l, functions_test, algorithms_test, reps, bounds, SafeData)\u001b[0m\n\u001b[0;32m    104\u001b[0m t_ \u001b[38;5;241m=\u001b[39m Test_function(i_function, N_x_, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m# algorithm\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m team_names, cids \u001b[38;5;241m=\u001b[39m i_algorithm(\n\u001b[0;32m    107\u001b[0m     t_, bounds_, f_eval_, i_rep\n\u001b[0;32m    108\u001b[0m )  \u001b[38;5;66;03m# X_opt_plot, TR_l, xnew, backtrck_l, samples_number are for plotting\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;66;03m# post-processing\u001b[39;00m\n\u001b[0;32m    110\u001b[0m X_all_pre \u001b[38;5;241m=\u001b[39m t_\u001b[38;5;241m.\u001b[39mx_list\n",
      "File \u001b[1;32mc:\\Users\\johnj\\OneDrive - Imperial College London\\Python\\Imperial-ML4CE-Course\\cw1_ddo\\part2_constrained\\ML4CE_WO_MyAlg.py:149\u001b[0m, in \u001b[0;36mYourAlg\u001b[1;34m(problem, bounds, budget, rep)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m con1(np\u001b[38;5;241m.\u001b[39marray(X_next)) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.12\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m con2(np\u001b[38;5;241m.\u001b[39marray(X_next)) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.08\u001b[39m:  \u001b[38;5;66;03m# Check the constraint\u001b[39;00m\n\u001b[0;32m    148\u001b[0m     Y_next \u001b[38;5;241m=\u001b[39m obj(np\u001b[38;5;241m.\u001b[39marray(X_next))\n\u001b[1;32m--> 149\u001b[0m     X_sample \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack((X_sample, np\u001b[38;5;241m.\u001b[39marray(X_next)))\n\u001b[0;32m    150\u001b[0m     Y_sample \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(Y_sample, Y_next)\n\u001b[0;32m    151\u001b[0m     gp\u001b[38;5;241m.\u001b[39mfit(X_sample, Y_sample)\n",
      "File \u001b[1;32mc:\\Users\\johnj\\anaconda3\\Lib\\site-packages\\numpy\\core\\shape_base.py:289\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(tup, dtype, casting)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    288\u001b[0m     arrs \u001b[38;5;241m=\u001b[39m [arrs]\n\u001b[1;32m--> 289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _nx\u001b[38;5;241m.\u001b[39mconcatenate(arrs, \u001b[38;5;241m0\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype, casting\u001b[38;5;241m=\u001b[39mcasting)\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2 and the array at index 1 has size 1"
     ]
    }
   ],
   "source": [
    "info, trajectories = ML4CE_con_eval(N_x_l, f_eval_l, functions_test, algorithms_test, reps, bounds=bounds)\n",
    "### Rank will return NaNs when only a single algorithms is in algorithms_list\n",
    "test_res_raw, test_res_norm, vio_dict= ML4CE_con_table_coursework(trajectories, algorithms_test, functions_test, N_x_l)\n",
    "ML4CE_con_table_plot_coursework(info, test_res_raw, test_res_norm, vio_dict)\n",
    "ML4CE_con_graph_abs(trajectories, algorithms_test, functions_test, N_x_l)\n",
    "ML4CE_con_graph_abs_g1_coursework(trajectories, algorithms_test, functions_test, N_x_l)\n",
    "ML4CE_con_graph_abs_g2_coursework(trajectories, algorithms_test, functions_test, N_x_l)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
