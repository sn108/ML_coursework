{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This note book leads through the workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import all necessary information we need for our problem \n",
    "Do not change anything here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ML4CE_WO_algorithms import *\n",
    "from ML4CE_WO_utils import *\n",
    "from ML4CE_WO_MyAlg import *\n",
    "\n",
    "functions_test = [\"WO_f\"]\n",
    "\n",
    "# Number of input dimensions for WO\n",
    "N_x_l = [2]\n",
    "\n",
    "# Iterate from 10 different starting points\n",
    "reps = 10\n",
    "\n",
    "#  Specify budget\n",
    "f_eval_l = [20]\n",
    "\n",
    "# Specify bounds\n",
    "bounds = np.array([[4.0, 7.0], [70.0, 100.0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's specify the algorithms we want to use. Your \"competitors\" in the group work will be your classmates. However, we've decided to give you some (quite capable) sparring partners here - don't worry if your algorithm's performance does not live up to these standards, as your grading will be wtih respect to your classmates performances :-). Once you've coded your algorithm in `ML4CE_WO_algorithms.py` you may add it's name in the following list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms_test = [\n",
    "    COBYLA, \n",
    "    YourAlg\n",
    "    #### add name of your algorithm here #####\n",
    "    # after we make a function, we add it here #\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here on, you should be able to run each of the following cells. The first function `ML4CE_con_eval` evaluates your algorithm from 10 different starting points (=10 reps) with a budget of 20 objective function evaluations per repetition. Then `ML4CE_con_graph_abs` and `ML4CE_con_graph_abs_g1_coursework` will visualize the convergence of your algorithm and the sparring partners performance, as well as the constraint handling. Finally, `ML4CE_con_table_coursework` and `ML4CE_con_table_plot_coursework` will apply the benchmarking procedure based on the trajectories and will summarize the results in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================  WO_f D2\n",
      "==  COBYLA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==  YourAlg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m info, trajectories \u001b[38;5;241m=\u001b[39m ML4CE_con_eval(N_x_l, f_eval_l, functions_test, algorithms_test, reps, bounds\u001b[38;5;241m=\u001b[39mbounds)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m### Rank will return NaNs when only a single algorithms is in algorithms_list\u001b[39;00m\n\u001b[0;32m      3\u001b[0m test_res_raw, test_res_norm, vio_dict\u001b[38;5;241m=\u001b[39m ML4CE_con_table_coursework(trajectories, algorithms_test, functions_test, N_x_l)\n",
      "File \u001b[1;32mc:\\Users\\johnj\\OneDrive - Imperial College London\\Python\\Imperial-ML4CE-Course\\cw1_ddo\\part2_constrained\\ML4CE_WO_utils.py:106\u001b[0m, in \u001b[0;36mML4CE_con_eval\u001b[1;34m(N_x_l, f_eval_l, functions_test, algorithms_test, reps, bounds, SafeData)\u001b[0m\n\u001b[0;32m    104\u001b[0m t_ \u001b[38;5;241m=\u001b[39m Test_function(i_function, N_x_, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m# algorithm\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m team_names, cids \u001b[38;5;241m=\u001b[39m i_algorithm(\n\u001b[0;32m    107\u001b[0m     t_, bounds_, f_eval_, i_rep\n\u001b[0;32m    108\u001b[0m )  \u001b[38;5;66;03m# X_opt_plot, TR_l, xnew, backtrck_l, samples_number are for plotting\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;66;03m# post-processing\u001b[39;00m\n\u001b[0;32m    110\u001b[0m X_all_pre \u001b[38;5;241m=\u001b[39m t_\u001b[38;5;241m.\u001b[39mx_list\n",
      "File \u001b[1;32mc:\\Users\\johnj\\OneDrive - Imperial College London\\Python\\Imperial-ML4CE-Course\\cw1_ddo\\part2_constrained\\ML4CE_WO_MyAlg.py:114\u001b[0m, in \u001b[0;36mYourAlg\u001b[1;34m(problem, bounds, budget, rep)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# Gaussian Process\u001b[39;00m\n\u001b[0;32m    113\u001b[0m gp \u001b[38;5;241m=\u001b[39m Bayesian_Guassian(kernel\u001b[38;5;241m=\u001b[39mrbf_kernel)\n\u001b[1;32m--> 114\u001b[0m gp\u001b[38;5;241m.\u001b[39mfit(X_init, Y_init)\n\u001b[0;32m    116\u001b[0m \u001b[38;5;66;03m# Bayesian Optimization loop\u001b[39;00m\n\u001b[0;32m    117\u001b[0m n_iter \u001b[38;5;241m=\u001b[39m budget\n",
      "File \u001b[1;32mc:\\Users\\johnj\\OneDrive - Imperial College London\\Python\\Imperial-ML4CE-Course\\cw1_ddo\\part2_constrained\\ML4CE_WO_MyAlg.py:58\u001b[0m, in \u001b[0;36mYourAlg.<locals>.Bayesian_Guassian.fit\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(x)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(y)\n\u001b[1;32m---> 58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mK \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnoise \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39meye(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train))\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mK_inv \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39minv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mK)\n",
      "File \u001b[1;32mc:\\Users\\johnj\\OneDrive - Imperial College London\\Python\\Imperial-ML4CE-Course\\cw1_ddo\\part2_constrained\\ML4CE_WO_MyAlg.py:69\u001b[0m, in \u001b[0;36mYourAlg.<locals>.rbf_kernel\u001b[1;34m(X1, X2, length_scale)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrbf_kernel\u001b[39m(X1, X2, length_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m):\n\u001b[1;32m---> 69\u001b[0m     sqdist \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(X1\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39msum(X2\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(X1, X2\u001b[38;5;241m.\u001b[39mT)\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m/\u001b[39m length_scale \u001b[38;5;241m*\u001b[39m sqdist)\n",
      "File \u001b[1;32mc:\\Users\\johnj\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:2313\u001b[0m, in \u001b[0;36msum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2310\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m   2311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[1;32m-> 2313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _wrapreduction(a, np\u001b[38;5;241m.\u001b[39madd, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m, axis, dtype, out, keepdims\u001b[38;5;241m=\u001b[39mkeepdims,\n\u001b[0;32m   2314\u001b[0m                       initial\u001b[38;5;241m=\u001b[39minitial, where\u001b[38;5;241m=\u001b[39mwhere)\n",
      "File \u001b[1;32mc:\\Users\\johnj\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:88\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     86\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[1;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ufunc\u001b[38;5;241m.\u001b[39mreduce(obj, axis, dtype, out, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "info, trajectories = ML4CE_con_eval(N_x_l, f_eval_l, functions_test, algorithms_test, reps, bounds=bounds)\n",
    "### Rank will return NaNs when only a single algorithms is in algorithms_list\n",
    "test_res_raw, test_res_norm, vio_dict= ML4CE_con_table_coursework(trajectories, algorithms_test, functions_test, N_x_l)\n",
    "ML4CE_con_table_plot_coursework(info, test_res_raw, test_res_norm, vio_dict)\n",
    "ML4CE_con_graph_abs(trajectories, algorithms_test, functions_test, N_x_l)\n",
    "ML4CE_con_graph_abs_g1_coursework(trajectories, algorithms_test, functions_test, N_x_l)\n",
    "ML4CE_con_graph_abs_g2_coursework(trajectories, algorithms_test, functions_test, N_x_l)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
