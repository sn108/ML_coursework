{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This note book leads through the workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import all necessary information we need for our problem \n",
    "Do not change anything here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ML4CE_WO_algorithms import *\n",
    "from ML4CE_WO_utils import *\n",
    "from ML4CE_WO_MyAlg import *\n",
    "\n",
    "functions_test = [\"WO_f\"]\n",
    "\n",
    "# Number of input dimensions for WO\n",
    "N_x_l = [2]\n",
    "\n",
    "# Iterate from 10 different starting points\n",
    "reps = 10\n",
    "\n",
    "#  Specify budget\n",
    "f_eval_l = [20]\n",
    "\n",
    "# Specify bounds\n",
    "bounds = np.array([[4.0, 7.0], [70.0, 100.0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's specify the algorithms we want to use. Your \"competitors\" in the group work will be your classmates. However, we've decided to give you some (quite capable) sparring partners here - don't worry if your algorithm's performance does not live up to these standards, as your grading will be wtih respect to your classmates performances :-). Once you've coded your algorithm in `ML4CE_WO_algorithms.py` you may add it's name in the following list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms_test = [\n",
    "    #COBYLA, \n",
    "    YourAlg\n",
    "    #### add name of your algorithm here #####\n",
    "    # after we make a function, we add it here #\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here on, you should be able to run each of the following cells. The first function `ML4CE_con_eval` evaluates your algorithm from 10 different starting points (=10 reps) with a budget of 20 objective function evaluations per repetition. Then `ML4CE_con_graph_abs` and `ML4CE_con_graph_abs_g1_coursework` will visualize the convergence of your algorithm and the sparring partners performance, as well as the constraint handling. Finally, `ML4CE_con_table_coursework` and `ML4CE_con_table_plot_coursework` will apply the benchmarking procedure based on the trajectories and will summarize the results in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================  WO_f D2\n",
      "==  YourAlg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1 into shape (2,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m info, trajectories \u001b[38;5;241m=\u001b[39m ML4CE_con_eval(N_x_l, f_eval_l, functions_test, algorithms_test, reps, bounds\u001b[38;5;241m=\u001b[39mbounds)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m### Rank will return NaNs when only a single algorithms is in algorithms_list\u001b[39;00m\n\u001b[0;32m      3\u001b[0m test_res_raw, test_res_norm, vio_dict\u001b[38;5;241m=\u001b[39m ML4CE_con_table_coursework(trajectories, algorithms_test, functions_test, N_x_l)\n",
      "File \u001b[1;32mc:\\Users\\johnj\\OneDrive - Imperial College London\\Python\\Imperial-ML4CE-Course\\cw1_ddo\\part2_constrained\\ML4CE_WO_utils.py:106\u001b[0m, in \u001b[0;36mML4CE_con_eval\u001b[1;34m(N_x_l, f_eval_l, functions_test, algorithms_test, reps, bounds, SafeData)\u001b[0m\n\u001b[0;32m    104\u001b[0m t_ \u001b[38;5;241m=\u001b[39m Test_function(i_function, N_x_, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m# algorithm\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m team_names, cids \u001b[38;5;241m=\u001b[39m i_algorithm(\n\u001b[0;32m    107\u001b[0m     t_, bounds_, f_eval_, i_rep\n\u001b[0;32m    108\u001b[0m )  \u001b[38;5;66;03m# X_opt_plot, TR_l, xnew, backtrck_l, samples_number are for plotting\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;66;03m# post-processing\u001b[39;00m\n\u001b[0;32m    110\u001b[0m X_all_pre \u001b[38;5;241m=\u001b[39m t_\u001b[38;5;241m.\u001b[39mx_list\n",
      "File \u001b[1;32mc:\\Users\\johnj\\OneDrive - Imperial College London\\Python\\Imperial-ML4CE-Course\\cw1_ddo\\part2_constrained\\ML4CE_WO_MyAlg.py:107\u001b[0m, in \u001b[0;36mYourAlg\u001b[1;34m(problem, bounds, budget, rep)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m# Initial samples\u001b[39;00m\n\u001b[0;32m    106\u001b[0m X_init \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(x_start)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 107\u001b[0m Y_init \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(obj(X_init))\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;66;03m# Bounds for the search space\u001b[39;00m\n\u001b[0;32m    110\u001b[0m bounds \u001b[38;5;241m=\u001b[39m bounds\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 1 into shape (2,)"
     ]
    }
   ],
   "source": [
    "info, trajectories = ML4CE_con_eval(N_x_l, f_eval_l, functions_test, algorithms_test, reps, bounds=bounds)\n",
    "### Rank will return NaNs when only a single algorithms is in algorithms_list\n",
    "test_res_raw, test_res_norm, vio_dict= ML4CE_con_table_coursework(trajectories, algorithms_test, functions_test, N_x_l)\n",
    "ML4CE_con_table_plot_coursework(info, test_res_raw, test_res_norm, vio_dict)\n",
    "ML4CE_con_graph_abs(trajectories, algorithms_test, functions_test, N_x_l)\n",
    "ML4CE_con_graph_abs_g1_coursework(trajectories, algorithms_test, functions_test, N_x_l)\n",
    "ML4CE_con_graph_abs_g2_coursework(trajectories, algorithms_test, functions_test, N_x_l)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
